<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[在windows上搭建superset]]></title>
      <url>%2F2017%2F10%2F15%2F%E5%9C%A8windows%E4%B8%8A%E6%90%AD%E5%BB%BAsuperset%2F</url>
      <content type="text"><![CDATA[——三尺青锋怀天下，一骑白马开吴疆。 安装文档：http://superset.apache.org/installation.html 创建虚拟环境pip install superset 激活虚拟环境superset\Scripts\activate superset 初始化的事情基本与文档一致，只是需要切换到envs\superset\Scripts下，将所有superset替换成python superset1234567891011121314151617181920# Install supersetpip install superset# Create an admin user (you will be prompted to set username, first and last name before setting a password)fabmanager create-admin --app superset# Initialize the databasepython superset db upgrade# Load some data to play withpython superset load_examples# Create default roles and permissionspython superset init# Start the web server on port 8088, use -p to bind to another portpython superset runserver# To start a development web server, use the -d switch# python superset runserver -d 连接数据库进行可视化打开http://localhost:8088，输入原先设置好的账号密码即可登陆。登陆后打开sources-databases，新建一个数据库连接，如下图修改相关信息即可，之后就可以使用sql提取数据并进行可视化了。 相关问题 sasl.h找不到：下载合适版本的whl文件手动安装http://www.lfd.uci.edu/~gohlke/pythonlibs/#sasl。 “module” object has no attribute ‘SIGALRM‘错误：windows下依赖包不兼容，把signal所在行都注释，下面再加一个pass就好了，文件在superset/utils.py。 localhost:8088无法打开：可能是所处环境设置了代理，使用火狐浏览器设置无代理模式或者使用内网ip进行访问。 由于 gunicorn 不支持 Windows，所以只能运行开发环境。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[文本相似度]]></title>
      <url>%2F2017%2F07%2F23%2F%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6%2F</url>
      <content type="text"><![CDATA[——小本本上八卦羞答答,人生太复杂 研究什么 最长公共子串 最长公共子序列 最少编辑距离法 汉明距离 余弦相似度 那就开始最长公共子串(The Longest Common Substring)根据这个blog简单整理一下用一个矩阵来记录两个字符串中所有位置的两个字符之间的匹配情况，若是匹配则为1,否则为0。然后求出对角线最长的1的序列，其对应的位置就是最长匹配子串的位置。123456789101112def find_lcsubstr(s1, s2): m=[[0 for i in range(len(s2)+1)] for j in range(len(s1)+1)] #生成0矩阵，为方便后续计算，比字符串长度多了一列 mmax=0 #最长匹配的长度 p=0 #最长匹配对应在s1中的最后一位 for i in range(len(s1)): for j in range(len(s2)): if s1[i]==s2[j]: m[i+1][j+1]=m[i][j]+1 if m[i+1][j+1]&gt;mmax: mmax=m[i+1][j+1] p=i+1 return s1[p-mmax:p],mmax #返回最长子串及其长度 12In [7]: print find_lcsubstr('abcdfg','abdfg')('dfg', 3) 最长公共子序列同样是根据这个blog简单整理一下子串要求字符必须是连续的，但是子序列可以不连续，用动态规划的思想：一个矩阵记录两个字符串中匹配情况，若是匹配则为左上方的值加1，否则为左方和上方的最大值。一个矩阵记录转移方向，然后根据转移方向，回溯找到最长子序列。 123456789101112131415161718192021222324252627282930313233import numpy def find_lcseque(s1, s2): # 生成字符串长度加1的0矩阵，m用来保存对应位置匹配的结果 m = [ [ 0 for x in range(len(s2)+1) ] for y in range(len(s1)+1) ] # d用来记录转移方向 d = [ [ None for x in range(len(s2)+1) ] for y in range(len(s1)+1) ] for p1 in range(len(s1)): for p2 in range(len(s2)): if s1[p1] == s2[p2]: #字符匹配成功，则该位置的值为左上方的值加1 m[p1+1][p2+1] = m[p1][p2]+1 d[p1+1][p2+1] = 'ok' elif m[p1+1][p2] &gt; m[p1][p2+1]: #左值大于上值，则该位置的值为左值，并标记回溯时的方向 m[p1+1][p2+1] = m[p1+1][p2] d[p1+1][p2+1] = 'left' else: #上值大于左值，则该位置的值为上值，并标记方向up m[p1+1][p2+1] = m[p1][p2+1] d[p1+1][p2+1] = 'up' (p1, p2) = (len(s1), len(s2)) print numpy.array(d) s = [] while m[p1][p2]: #不为None时 c = d[p1][p2] if c == 'ok': #匹配成功，插入该字符，并向左上角找下一个 s.append(s1[p1-1]) p1-=1 p2-=1 if c =='left': #根据标记，向左找下一个 p2 -= 1 if c == 'up': #根据标记，向上找下一个 p1 -= 1 s.reverse() return ''.join(s) 最少编辑距离编辑距离，又称Levenshtein距离，是指两个字串之间，由一个转成另一个所需的最少编辑操作次数 同样是动态规划问题，这个blog说的很清晰实际应用中直接调用python-Levenshtein这个包实现，毕竟能不造轮子就不造轮子。模块通过pip install python-Levenshtein==0.12.0 进行安装。例如： 123456In [3]: Levenshtein.distance('fadg','fdag')Out[3]: 2In [4]: Levenshtein.ratio('fadg','fdag')Out[4]: 0.75 汉明距离From WIKIPEDIA：The Hamming distance between two strings of equal length is the number of positions at which the corresponding symbols are different.和Levenshtein distance最大的区别是Hamming distance只算替换不算插入删除。同样能不造轮子就不造轮子，这个函数要求两个字符串长度要相等。12In [7]: Levenshtein.hamming('fadgsa','fdadag')Out[7]: 5 余弦相似度基本公式： 拓展：修正余弦相似度与pearson相关系数 修正cosine考虑的是对item i打过分的每个user u，其打分的均值 Pearson考虑的是每个item i 的被打分的均值 写到这里，有一篇关于词袋模型、TF-IDF模型和LSI模型的blog值得看一下。就到这里吧！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[图像像素块统计（with OpenCV）]]></title>
      <url>%2F2017%2F06%2F06%2F%E5%9B%BE%E5%83%8F%E5%83%8F%E7%B4%A0%E5%9D%97%E7%BB%9F%E8%AE%A1%EF%BC%88with%20openCV%EF%BC%89%2F</url>
      <content type="text"><![CDATA[——十年热血写信仰，荣耀永不散场 只有一个问题，统计如下测试素材图中有多少个连在一起的像素块。 实现过程基本参考这篇文章简单修改，测试结果为13个像素块，原理不懂，看着看着才发现这个需求就是数细胞啊，当年还听老师讲过，我居然没有第一时间反应过来，Anyway，感谢google。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# -*- coding: utf-8 -*-import numpy as npimport imutilsimport cv2def counter(filename): counter = &#123;&#125; image_orig = cv2.imread(filename) height_orig, width_orig = image_orig.shape[:2] # output image with contours image_contours = image_orig.copy() # DETECTING BLUE AND WHITE COLONIES colors = ['red'] for color in colors: # copy of original image image_to_process = image_orig.copy() # initializes counter counter[color] = 0 # define NumPy arrays of color boundaries (GBR vectors) if color == 'red': lower = np.array([ 0, 0, 255]) upper = np.array([ 0, 0, 255]) # find the colors within the specified boundaries image_mask = cv2.inRange(image_to_process, lower, upper) # apply the mask image_res = cv2.bitwise_and(image_to_process, image_to_process, mask = image_mask) ## load the image, convert it to grayscale, and blur it slightly image_gray = cv2.cvtColor(image_res, cv2.COLOR_BGR2GRAY) image_gray = cv2.GaussianBlur(image_gray, (5, 5), 0) # perform edge detection, then perform a dilation + erosion to close gaps in between object edges image_edged = cv2.Canny(image_gray, 50, 100) image_edged = cv2.dilate(image_edged, None, iterations=1) image_edged = cv2.erode(image_edged, None, iterations=1) # find contours in the edge map cnts = cv2.findContours(image_edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) cnts = cnts[0] if imutils.is_cv2() else cnts[1] # loop over the contours individually for c in cnts: # if the contour is not sufficiently large, ignore it if cv2.contourArea(c) &lt; 5: continue # compute the Convex Hull of the contour hull = cv2.convexHull(c) if color == 'red': # prints contours in red color cv2.drawContours(image_contours,[hull],0,(0,0,0),1) counter[color] += 1 #cv2.putText(image_contours, "&#123;:.0f&#125;".format(cv2.contourArea(c)), (int(hull[0][0][0]), int(hull[0][0][1])), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (255, 255, 255), 2) # Print the number of colonies of each color return counter[color] #print("&#123;&#125; &#123;&#125; colonies".format(counter[color],color)) # Writes the output image # cv2.imwrite(args["output"],image_contours)if __name__ == '__main__': print counter(u'test.png') 主要坑点1、 没法直接安装cv2，通过pip install opencv-python安装opencv,后import cv2成功。2、 这里最难的应该是设置合适的像素值，红色的RGB代码是（255，0，0），但是这里lower = np.array([ 0, 0, 255]),用的是GBR（叫你不认真看注释）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[pyttsx 文本转语音]]></title>
      <url>%2F2017%2F03%2F12%2Fpyttsx-%E6%96%87%E6%9C%AC%E8%BD%AC%E8%AF%AD%E9%9F%B3%2F</url>
      <content type="text"><![CDATA[感觉挺有趣，不是很难，权当记录一下简单的实现方式，其他API实现可参考doc： 12345678910111213141516import pyttsxengine = pyttsx.init()# set voicevoices = engine.getProperty('voices')engine.setProperty('voice', voices[0])# set raterate = engine.getProperty('rate')engine.setProperty('rate', rate+30)text = u'中央电视台，中央电视台!'engine.say(text)# save to mp3.fileengine.speakToFile(text, r"./123.mp3")engine.runAndWait() 设置输出到文件 pyttsx的官方版本不支持在windows系统下输出到文件，通过下载github上的修改版本，在将其替代原来安装的版本,可以在python shell中,通过import pyttsx和pyttsx,找到pyttsx的位置。 安装comtypes、 win32com,并修改pyttsx里的sapi5.py文件，将comtypes的导入语句修改为：1234from comtypes.client import CreateObjectengine = CreateObject("SAPI.SpVoice")stream = CreateObject("SAPI.SpFileStream")from comtypes.gen import SpeechLib 参考 http://blog.wojiaohgl.com/archives/267]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[词云制作]]></title>
      <url>%2F2017%2F03%2F04%2F%E8%AF%8D%E4%BA%91%E5%88%B6%E4%BD%9C%2F</url>
      <content type="text"><![CDATA[——你有最美的眼睛倒映着辰星，有最美的颜色如彩虹般绚丽 两种方式制作词云 使用wordcloud制作词云效果可以直接使用默认设置，或自定义设置（default_color）（costom_color） 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# -*- coding:utf-8 -*-import numpy as npfrom PIL import Imagefrom os import pathimport matplotlib.pyplot as pltimport randomimport osfrom wordcloud import WordCloud, STOPWORDSfont=os.path.join(os.path.dirname(__file__), "msyh.ttf")def grey_color_func(word, font_size, position, orientation, random_state=None, **kwargs): return "hsl(0, 0%%, %d%%)" % random.randint(60, 100)d = path.dirname(__file__)mask = np.array(Image.open(path.join(d, "timg.jpg")))# 词云定制图片模板text = open(u"test.txt").read().decode('utf-8')# adding movie script specific stopwordsstopwords = set(STOPWORDS)stopwords.add("int")stopwords.add("ext")wc = WordCloud(font_path=font, max_words=2000, background_color='black', mask=mask, stopwords=stopwords, margin=10, random_state=1).generate(text)# default colored imagedefault_colors = wc.to_array()plt.title(u"词云制作")plt.imshow(default_colors)plt.axis("off")wc.to_file("default_color.png")plt.show()# costom colored imageplt.figure()plt.title(u"词云制作")plt.imshow(wc.recolor(color_func=grey_color_func, random_state=3))wc.to_file("costom_color.png")plt.axis("off")plt.show() wordcloud的中文显示需要指定font参数文件，本例使用系统字体msyh.ttf，可以直接从系统字体库中复制过来，修改后缀名为ttf即可 使用jieba、Taguljieba分词12345678910111213141516# -*- coding:utf-8 -*-import jieba.analyseimport osimport codecsd = os.path.dirname(__file__)file_name = os.path.join(d, "test.txt")with codecs.open(file_name, 'rb', encoding='utf-8', errors='ignore') as f: content = f.read()tags = jieba.analyse.extract_tags(content, topK=2000, withWeight=False, allowPOS=())# tags = jieba.analyse.extract_tags(content, topK=2000, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'))outputfile = os.path.join(d, 'out.txt')with codecs.open(outputfile, 'w', encoding='utf-8', errors='ignore') as w: for i in tags: w.write(i + '\n') tagul打开tagul注册或登陆后，将jieba分词之后的结果（已经根据词频排序），import words导入，调整合适的配置和参数，输出即可。 （不过滤词性）（过滤词性） 使用的是tagul页面版，需要导入中文支持，测试中发现不支持微软雅黑，支持华文细黑。 jieba分词是否经过词性过滤，对结果有较大影响，根据实际情况调整 wordcloud支持输入整个文本，tagul支持输入排好序的关键词，两种方法的结果有比较大的差异，词云的制作比较依赖算法，孰优孰劣，权衡使用 参考 https://github.com/amueller/word_cloud https://www.shiyanlou.com/courses/756/labs/2521/document https://github.com/fxsjy/jieba/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[matplotlib 初体验]]></title>
      <url>%2F2017%2F02%2F26%2Fmatplotlib-%E5%88%9D%E4%BD%93%E9%AA%8C%2F</url>
      <content type="text"><![CDATA[——愿你不惧荒唐，敢爱如初 从需求出发，第一次体验matplotlib模块。 需求描述为每位玩家生成一张图表，反映其在过去一周游戏货币来源途径的占比，以及其与人工预设的上一阶层的来源对比情况。效果如下： 生成简单的条形图参考文档内容：barchart_demo.py代码已经很接近需求，稍微修改一下，设置了不透明度参数、使用中文标注和稍微修改了一下颜色。实现效果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# -*- coding:utf-8 -*-import numpy as npimport matplotlib.pyplot as pltN = 5yoursdata = (20, 35, 30, 35, 27)men_std = (2, 3, 4, 1, 2)ind = np.arange(N) # the x locations for the groupswidth = 0.35 # the width of the barsopacity = 0.4 # 不透明级别fig, ax = plt.subplots()rects1 = ax.bar(ind, yoursdata, width, color='b', alpha=opacity, yerr=men_std)target_data = (25, 32, 34, 20, 25)women_std = (3, 5, 2, 3, 3)rects2 = ax.bar(ind + width, target_data, width, color='r', alpha=opacity, yerr=women_std)# add some text for labels, title and axes ticksax.set_ylabel(u'数量(单位：万)')ax.set_title(u'金币周获得量对比图')ax.set_xticks(ind + width)ax.set_xticklabels(('way1', 'way2', 'way3', 'way4', 'way5'))ax.legend((rects1[0], rects2[0]), (u'您', u'对比群体'))def autolabel(rects): """ Attach a text label above each bar displaying its height """ for rect in rects: height = rect.get_height() ax.text(rect.get_x() + rect.get_width()/2., 1.05*height, '%d' % int(height), ha='center', va='bottom')autolabel(rects1)autolabel(rects2)plt.show() 对于ax.legend()的设置，也可以直接在ax.bar创建是赋以参数label,然后调用ax.legend()即可，不用再次传入参数： 12345rects1 = ax1.bar(index, yoursdata, bar_width, alpha=opacity, color='b', label=u'您')ax1.legend() matplotlib默认不支持在label等参数中传入中文，这里有三种解决办法，笔者直接尝试了第三种方法，成功解决问题 生成简单的饼形图(同理，比较简单，不赘述。)参考文档内容：pie_demo_features.py 两张图合并成一张参考文档内容：subplots_demo.py 只需要创建两个subplot，分别绘制bar和pie即可，以下三种创建subplot的写法效果一致。到这里，基本上已经完成了整个思路，最后可能需要通过plt.figure()对象的一些参数调节整个图的呈现效果，细节不详述。 1234567891011121314151617181920212223242526x = np.linspace(0, 2 * np.pi, 400)y = np.sin(x ** 2)plt.close('all')# Two subplots, the axes array is 1-df, axarr = plt.subplots(2, sharex=True)axarr[0].plot(x, y)axarr[0].set_title('Sharing X axis')axarr[1].scatter(x, y)# Two subplots, unpack the axes array immediatelyf, (ax1, ax2) = plt.subplots(2, 1, sharex=True) # 两行一列ax1.plot(x, y)ax1.set_title('Sharing X axis')ax2.scatter(x, y)# Two subplots, unpack the axes array immediatelyfig = plt.figure()ax1 = fig.add_subplot(211) # 两行一列第一个ax2 = fig.add_subplot(212) # 两行一列第二个ax1.plot(x, y)ax1.set_title('Sharing X axis')ax2.scatter(x, y)plt.show() 保存图片plt.show()只展示绘图界面，无法实现保存，保存命令需要用到fig.savefig()和fig.close(),在循环中调用时，如果不使用fig.close()，其效果是在上一张图的基础上继续作图。 最后，读取数据文件，循环生成图片即可，这里我使用json格式存储数据，结构如下： 1234567891011&#123;"role_id2":&#123;"selfget_top5":&#123;"way1":10,"way2":14,"way3":12,"way4":7,"way5":3&#125;,"cha_self_top5":&#123;"wayA":15,"wayB":13,"wayC":12,"wayD":7,"wayE":6&#125;,"cha_target_top5":&#123;"wayA":19,"wayB":17,"wayC":14,"wayD":8,"wayE":7&#125;&#125;,"role_id1":&#123;"selfget_top5":&#123;"way1":15,"way2":13,"way3":12,"way4":7,"way5":3&#125;,"cha_self_top5":&#123;"wayA":15,"wayB":13,"wayC":12,"wayD":7,"wayE":7&#125;,"cha_target_top5":&#123;"wayA":19,"wayB":17,"wayC":14,"wayD":8,"wayE":7&#125;&#125;&#125; 最后，未经优化，基本满足需求的脚本： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899# -*- coding:utf-8 -*-"""Bar chart demo with pairs of bars grouped for easy comparison."""import numpy as npimport jsonimport codecsimport matplotlib.pyplot as pltdef get_explode(selfdata): explode = [0, 0, 0, 0, 0] a = selfdata.index(max(selfdata)) explode.pop(a) explode.insert(a, 0.1) return explodedef autolabel(rects, ax): """ Attach a text label above each bar displaying its height """ for rect in rects: height = rect.get_height() ax.text(rect.get_x() + rect.get_width() / 2., 1.05 * height, '%d' % int(height), ha='center', va='bottom')def jinbiduibitu(filename, selfdata, selftujing, yoursdata, targetdata, tujinglist, explode): N = 5 labels = selftujing sizes = selfdata men_std = (2, 3, 4, 1, 2) ind = np.arange(N) # the x locations for the groups width = 0.35 # the width of the bars opacity = 0.4 # 不透明度 fig = plt.figure() ax1 = fig.add_subplot(211) ax2 = fig.add_subplot(212) rects1 = ax1.bar(ind, yoursdata, width, color='b', alpha=opacity, yerr=men_std) women_std = (2, 3, 4, 1, 2) rects2 = ax1.bar(ind + width, targetdata, width, color='r', alpha=opacity, yerr=women_std) # add some text for labels, title and axes ticks ax1.set_ylabel(u'数量(单位：万)') ax1.set_title(u'金币周获得量对比图') ax1.set_xticks(ind + width) ax1.set_xticklabels(tujinglist) autolabel(rects1, ax1) autolabel(rects2, ax1) ax1.legend((rects1[0], rects2[0]), (u'您', u'对比群体')) piecs = ['red', 'yellow', 'Maroon', 'blue', 'Orange'] ax2.pie(sizes, colors=piecs, explode=explode, labels=labels, autopct='%1.2f%%', shadow=True, startangle=90) ax2.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. ax2.set_title(u'个人金币周获得量渠道占比图', x=0.5,y=1.1) fn = './barchart_demo_output/' + filename + '.png' fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.4) # 调整图间距 #plt.show() plt.savefig(fn) plt.close()if __name__ == '__main__': with codecs.open('barchart_demo_input.txt', 'r', encoding = 'utf-8', errors = 'ignore') as f: d = json.load(f) print len(d) for i in d.keys(): filename = i tujinglist = d[i]['cha_self_top5'].keys() selfdata = [] selftujing = d[i]['selfget_top5'].keys() for k in selftujing: sg = d[i]['selfget_top5'][k] selfdata.append(sg) yoursdata = [] targetdata = [] for j in tujinglist: yd = d[i]['cha_self_top5'][j] td = d[i]['cha_target_top5'][j] yoursdata.append(yd) targetdata.append(td) explode = get_explode(selfdata) jinbiduibitu(filename,selfdata, selftujing, yoursdata, targetdata, tujinglist, explode)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python多进程与多线程]]></title>
      <url>%2F2017%2F02%2F12%2Fpython%E5%A4%9A%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[——五花马,千金裘,呼儿将出换美酒,与尔同销万古愁。 越来越觉得自己对这些东西一知半解…折腾了好久，今天整理一下我一知半解的 python多进程与多线程 毕竟每周还是应该多少有点什么值得记下来… 首先理解：进程&gt;线程（不知道可不可以这样讲），进程里至少有一个线程，线程之间共享内存空间，有其他进程占用内存空间时，需要等待内存闲置。一篇文章：关于进程和线程区别的类比：http://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html 多进程1.创建多进程的：使用multiprocessing模块的Process类 12345678910111213141516from multiprocessing import Processimport osdef test(name): # os模块的getpid()方法可以获取当前进程的进程id print 'Run process %s (%s)...' % (name, os.getpid())if __name__ == '__main__': print 'Main process %s.' % os.getpid() # 创建一个进程 p = Process(target=test, args=('process1',)) p.start() # 调用start()方法，开始执行子进程 p.join() # 调用进程的join()方法，来阻塞除当前进程以外的所有进程,相当于是上锁的操作 print 'test finished!' 2.依次创建进程进行一次计算并测试效率 123456789101112131415161718192021222324252627282930313233from multiprocessing import Processimport timedef test(num): sum = 0 for i in range(0, num): sum += i return sumif __name__ == '__main__': start_time = time.time() test(10000000) test(10000000) test(10000000) last_time = time.time() - start_time print last_time # 常规写法，耗时2.85500001907s p1 = Process(target=test, args=(10000000,)) p2 = Process(target=test, args=(10000000,)) p3 = Process(target=test, args=(10000000,)) p1.start() p2.start() p3.start() p1.join() p2.join() p3.join() # 多进程写法，耗时1.36999988556s 这里开启进程时要注意一点：先把所有.start()写完，再写.join(),这样发生进程阻塞的情况要少，这样就能充分发挥利用cpu，提高执行效率。 3.使用进程池的方式创建进程 12345678910111213141516171819202122232425262728from multiprocessing import Poolimport timedef test(num): sum = 0 for i in range(0, num): sum += i return sumdef test_test(num): a = test(num) b = test(num) c = test(num) return a+b+cif __name__ == '__main__': start_time = time.time() pool = Pool(processes=3) result = pool.apply_async(test_test, args=(10000000,)) pool.close() pool.join() print result.get() # 如果不获取结果，效率会高很多 last_time = time.time() - start_time print last_time# 耗时：3.21100020409s 注意两点： 调用join之前，先调用close函数，否则会出错。执行完close后不会有新的进程加入到pool。 apply和apply_async的区别：apply主进程会阻塞于函数，主进程的执行流程同单进程一样；apply_async是非阻塞的且支持结果返回后进行回调，主进程循环运行过程中不等待apply_async的返回结果，在主进程结束后，即使子进程还未返回整个程序也会退出。虽然apply_async是非阻塞的，但其返回结果的get方法却是阻塞的，如使用result.get()会阻塞主进程。对返回结果不感兴趣， 那么可以在主进程中使用pool.close与pool.join来防止主进程退出。注意join方法一定要在close或terminate之后调用。 Pool相关函数：https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.pool 4.使用Pool的map方法，进行多进程（cpu密集型任务）操作伪代码 1234567891011121314from multiprocessing import Pooldef method1(): return 被处理元素列表def method2(): 进行处理的方法if __name__ == '__mian__': pool = Pool() pool.map(method2, method1的结果) pool.close() pool.join() 多线程多线程适用于io密集型的任务，暂时只记使用multiprocessing.dummy这一种实现方法 12345678910111213141516171819202122232425262728import urllib2 from multiprocessing.dummy import Pool as ThreadPool urls = [ 'http://www.python.org', 'http://www.python.org/about/', 'http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html', 'http://www.python.org/doc/', 'http://www.python.org/download/', 'http://www.python.org/getit/', 'http://www.python.org/community/', 'https://wiki.python.org/moin/', 'http://planet.python.org/', 'https://wiki.python.org/moin/LocalUserGroups', 'http://www.python.org/psf/', 'http://docs.python.org/devguide/', 'http://www.python.org/community/awards/' # etc.. ]# Make the Pool of workerspool = ThreadPool(4) # Open the urls in their own threads# and return the resultsresults = pool.map(urllib2.urlopen, urls)#close the pool and wait for the work to finish pool.close() pool.join() 总结几句： IO 密集型任务选择multiprocessing.dummy，CPU 密集型任务选择multiprocessing 关于IO 密集型和CPU 密集型：所谓IO密集型任务，是指磁盘IO、网络IO占主要的任务，计算量很小。比如请求网页、读写文件等。所谓计算密集型任务，是指CPU计算占主要的任务，CPU一直处于满负荷状态。比如在一个很大的列表中查找元素，复杂的加减乘除等。 文章参考： 一行 Python 实现并行化 – 日常多线程操作的新思路 python 中多进程以及多线程编程的总结 ——写的过程中还看到了进程之间的通信与同时操作一个文件的进程锁的相关内容，只能慢慢来咯…]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python collections]]></title>
      <url>%2F2017%2F01%2F08%2Fpython-collections%2F</url>
      <content type="text"><![CDATA[具体实现方法参考文档：https://docs.python.org/3/library/collections.html container datetypes abstract Cool deque 双端序列 有得必有失 Counter 统计hashable objects 类似sql中的sum(A)…group by id OrderedDict 顺序存取的字典 None defaultdict key不存在时，赋予value默认值 实时统计玩家参与某副本的次数 namedtuple() 使tuple内的元素有自己的名称 坐标（x，y） 还有一些其他的类如ChainMap，暂时未归纳 defaultdict这个类想到的一些东西 在实时获取玩家参与某个玩家的次数时，由于玩家id唯一，一般作为key，使用dict比较方便，还可以应用json （听说有另外一个ujson更好用，慢慢看吧）格式进行交互，但是一开始没有进入统计范围的玩家，获取key时会报错，使用defaultdict可以解决这个问题 1234567891011# 普通字典In [7]: d = &#123;&#125;In [8]: d['a']---------------------------------------------------------------------------KeyError Traceback (most recent call last)&lt;ipython-input-8-169a40407b7f&gt; in &lt;module&gt;()----&gt; 1 d['a']KeyError: 'a' 1234567# defaultdictIn [4]: from collections import defaultdictIn [5]: d = defaultdict(int)In [6]: d['a']Out[6]: 0 实现hive中collect_all() 函数的函数,本来想在sqlite3上实现一下，但貌似不支持这个方法。 color count yellow 1 blue 2 yellow 3 blue 4 red 1 hive sql：1select color, collect_list(count) from test group by color difaultdict：12345678910In [19]: s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]In [20]: d = defaultdict(list)In [21]: for k, v in s: ...: d[k].append(v) ...:In [22]: dOut[22]: defaultdict(list, &#123;'blue': [2, 4], 'red': [1], 'yellow': [1, 3]&#125;) 图床抽风用不了截图，就凑合着，中午没吃饭，又困又饿…]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[openpyxl操作excel文件]]></title>
      <url>%2F2016%2F12%2F31%2Fopenpyxl%E6%93%8D%E4%BD%9Cexcel%E6%96%87%E4%BB%B6%20%2F</url>
      <content type="text"><![CDATA[这个完全是为了熟悉hexo和markdown语法，上周末生日，来自一位朋友的工作需求 需求描述需要将目录中的每一行数据分别建立单独的工作表，应用工作表1的模板，并填入对于应的数据（红色框部分） 实现效果： 实现过程第一步：批量生成指定名称的工作表，excel可直接操作 选中“桥梁名称”列，先Alt+D，再Alt+P，插入数据透视表 在数据透视表字段，将“桥梁名称”拖拽到筛选区域 透视表“选项”，选择“显示报表筛选页”，确定 参考：http://jingyan.baidu.com/article/6fb756ec8c6703241858fbba.html 第二步：复制模板到各个工作表这里只需要复制模板，全选模板内容，按住shift全选工作表，Ctrl+V复制即可 第三步：填入数据这应该是可以直接用excel完成的，比较菜，不会，选择了python openpyxl 模块操作excel的方式参考openpyxl文档：http://openpyxl.readthedocs.io/en/default/usage.html 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# -*- coding:utf-8 -*-from openpyxl import load_workbookwb = load_workbook(filename = u"xxx.xlsx")ws1 = wb.get_sheet_by_name(wb.get_sheet_names()[-2])print ws1.titlehangshu = ws1.get_highest_row()content = &#123;&#125;def get_content(): for i in range(2,217): if i &lt; 11: key = '00' + str(i-1) elif i &lt; 101: key = '0' + str(i-1) else: key = str(i-1) name_index = 'C' + str(i) bianhao_index = 'B' + str(i) dengji_index = 'H' + str(i) xunhao_index = 'K' + str(i) name = ws1[name_index].value keyname = key + name bianhao = ws1[bianhao_index].value dengji = ws1[dengji_index].value xunhao = ws1[xunhao_index].value content[keyname] = [bianhao, dengji, xunhao, name] return contentcontent = get_content()ll = 0for j in wb.get_sheet_names(): print j print content[j][3] wb.get_sheet_by_name(j)['B3'] = content[j][3] wb.get_sheet_by_name(j)['D3'] = content[j][0] wb.get_sheet_by_name(j)['F3'] = content[j][1] wb.get_sheet_by_name(j)['F26'] = content[j][2] ll += 1 if ll &gt; 214: break wb.save(filename = 'aaa_test1.xlsx')]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hello-world]]></title>
      <url>%2F2016%2F12%2F24%2Fhello-world%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
    </entry>

    
  
  
</search>
